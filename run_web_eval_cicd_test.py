#!/usr/bin/env python3
"""
Web-Eval-Agent CICD Cycle Test Runner
Runs comprehensive UI testing using web-eval-agent with CICD cycle instructions
"""

import os
import sys
import subprocess
import time
import json
import requests
from pathlib import Path
from typing import Dict, Any, Optional

class WebEvalCICDTester:
    def __init__(self, target_url: str = "http://localhost:3001"):
        self.target_url = target_url
        self.instructions_file = "cicd_cycle_instructions.txt"
        self.web_eval_agent_url = os.getenv("WEB_EVAL_AGENT_URL", "http://localhost:8003")
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.results_file = "web_eval_cicd_results.json"
        
    def check_prerequisites(self) -> bool:
        """Check if all prerequisites are met"""
        print("ðŸ” Checking prerequisites...")
        
        # Check if instructions file exists
        if not Path(self.instructions_file).exists():
            print(f"âŒ Instructions file not found: {self.instructions_file}")
            return False
        
        # Check if Gemini API key is set
        if not self.gemini_api_key:
            print("âŒ GEMINI_API_KEY environment variable not set")
            return False
        
        # Check if target URL is accessible
        try:
            response = requests.get(self.target_url, timeout=10)
            if response.status_code == 200:
                print(f"âœ… Target URL accessible: {self.target_url}")
            else:
                print(f"âš ï¸  Target URL returned {response.status_code}: {self.target_url}")
        except Exception as e:
            print(f"âš ï¸  Target URL not accessible: {e}")
            print("   Continuing anyway - may be testing production URL")
        
        print("âœ… Prerequisites check completed")
        return True
    
    def prepare_environment_variables(self) -> Dict[str, str]:
        """Prepare environment variables for the test"""
        env_vars = {
            "CODEGEN_ORG_ID": os.getenv("CODEGEN_ORG_ID", "323"),
            "CODEGEN_API_TOKEN": os.getenv("CODEGEN_API_TOKEN", ""),
            "GITHUB_TOKEN": os.getenv("GITHUB_TOKEN", ""),
            "GEMINI_API_KEY": self.gemini_api_key,
            "CLOUDFLARE_API_KEY": os.getenv("CLOUDFLARE_API_KEY", ""),
            "CLOUDFLARE_ACCOUNT_ID": os.getenv("CLOUDFLARE_ACCOUNT_ID", ""),
            "CLOUDFLARE_WORKER_NAME": os.getenv("CLOUDFLARE_WORKER_NAME", "webhook-gateway"),
            "CLOUDFLARE_WORKER_URL": os.getenv("CLOUDFLARE_WORKER_URL", ""),
            "TARGET_URL": self.target_url,
            "HEADLESS": "true",
            "TIMEOUT": "30000",
            "SCREENSHOT_ON_FAILURE": "true",
            "GENERATE_REPORT": "true"
        }
        
        # Filter out empty values
        return {k: v for k, v in env_vars.items() if v}
    
    def run_web_eval_agent_test(self) -> Dict[str, Any]:
        """Run the web-eval-agent test using our instructions"""
        print("ðŸš€ Starting Web-Eval-Agent CICD Cycle Test...")
        print(f"ðŸŽ¯ Target URL: {self.target_url}")
        print(f"ðŸ“‹ Instructions: {self.instructions_file}")
        
        # Prepare environment
        env_vars = self.prepare_environment_variables()
        test_env = os.environ.copy()
        test_env.update(env_vars)
        
        # Read instructions
        with open(self.instructions_file, 'r') as f:
            instructions = f.read()
        
        # Try to use web-eval-agent API if available
        try:
            return self.run_via_api(instructions, env_vars)
        except Exception as e:
            print(f"âš ï¸  API method failed: {e}")
            print("ðŸ”„ Falling back to direct browser automation...")
            return self.run_via_browser_automation(instructions, test_env)
    
    def run_via_api(self, instructions: str, env_vars: Dict[str, str]) -> Dict[str, Any]:
        """Run test via web-eval-agent API"""
        print("ðŸŒ Using Web-Eval-Agent API...")
        
        # Check if web-eval-agent API is available
        try:
            health_response = requests.get(f"{self.web_eval_agent_url}/health", timeout=5)
            if health_response.status_code != 200:
                raise Exception("Web-eval-agent API not healthy")
        except Exception as e:
            raise Exception(f"Web-eval-agent API not available: {e}")
        
        # Prepare test payload
        test_payload = {
            "url": self.target_url,
            "instructions": instructions,
            "environment": env_vars,
            "options": {
                "headless": True,
                "timeout": 900000,  # 15 minutes
                "screenshot_on_failure": True,
                "generate_report": True,
                "test_type": "complete_cicd_cycle"
            }
        }
        
        # Submit test
        print("ðŸ“¤ Submitting test to web-eval-agent...")
        response = requests.post(
            f"{self.web_eval_agent_url}/api/test/run",
            json=test_payload,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"Failed to submit test: {response.status_code}")
        
        test_id = response.json().get("test_id")
        print(f"âœ… Test submitted with ID: {test_id}")
        
        # Poll for results
        return self.poll_for_results(test_id)
    
    def run_via_browser_automation(self, instructions: str, test_env: Dict[str, str]) -> Dict[str, Any]:
        """Run test via direct browser automation"""
        print("ðŸ¤– Using direct browser automation...")
        
        # Create a simple browser automation script
        automation_script = self.create_automation_script(instructions)
        
        try:
            # Run the automation script
            result = subprocess.run(
                ["python", automation_script],
                env=test_env,
                capture_output=True,
                text=True,
                timeout=900  # 15 minutes
            )
            
            if result.returncode == 0:
                # Parse results from stdout
                return self.parse_automation_results(result.stdout)
            else:
                return {
                    "status": "failed",
                    "error": result.stderr,
                    "stdout": result.stdout
                }
                
        except subprocess.TimeoutExpired:
            return {
                "status": "timeout",
                "error": "Test execution timed out after 15 minutes"
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    def create_automation_script(self, instructions: str) -> str:
        """Create a browser automation script based on instructions"""
        script_content = f'''#!/usr/bin/env python3
"""
Generated browser automation script for CICD cycle testing
"""

import time
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options

def run_cicd_test():
    """Run the complete CICD cycle test"""
    results = {{
        "status": "running",
        "steps_completed": 0,
        "total_steps": 11,
        "errors": [],
        "screenshots": [],
        "performance_metrics": {{}},
        "start_time": time.time()
    }}
    
    # Setup Chrome options
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    
    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        
        # Step 1: Initial page load
        print("ðŸ” Step 1: Loading dashboard...")
        driver.get("{self.target_url}")
        
        # Wait for React to load
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "root"))
        )
        
        # Check for dashboard title
        title_found = "CodegenCICD" in driver.title or "CodegenCICD" in driver.page_source
        if title_found:
            print("âœ… Dashboard loaded successfully")
            results["steps_completed"] += 1
        else:
            results["errors"].append("Dashboard title not found")
        
        # Step 2: Check for project cards or add project button
        print("ðŸ” Step 2: Looking for project interface...")
        try:
            # Look for add project button or existing projects
            add_button = driver.find_element(By.XPATH, "//*[contains(text(), 'Add Project') or contains(text(), '+')]")
            print("âœ… Add project interface found")
            results["steps_completed"] += 1
        except:
            try:
                # Look for existing project cards
                project_cards = driver.find_elements(By.CSS_SELECTOR, "[data-testid*='project'], .project-card, .MuiCard-root")
                if project_cards:
                    print(f"âœ… Found {{len(project_cards)}} existing project(s)")
                    results["steps_completed"] += 1
                else:
                    results["errors"].append("No project interface found")
            except Exception as e:
                results["errors"].append(f"Project interface check failed: {{e}}")
        
        # Step 3: Basic UI validation
        print("ðŸ” Step 3: Validating UI components...")
        ui_checks = {{
            "material_ui": len(driver.find_elements(By.CSS_SELECTOR, ".MuiButton-root, .MuiCard-root, .MuiDialog-root")) > 0,
            "react_components": "react" in driver.page_source.lower(),
            "css_loaded": len(driver.find_elements(By.CSS_SELECTOR, "[class*='css-'], [class*='mui-']")) > 0,
            "js_loaded": len(driver.execute_script("return Object.keys(window).filter(k => k.includes('React') || k.includes('__REACT'))")) > 0
        }}
        
        passed_checks = sum(ui_checks.values())
        print(f"âœ… UI validation: {{passed_checks}}/{{len(ui_checks)}} checks passed")
        if passed_checks >= len(ui_checks) // 2:
            results["steps_completed"] += 1
        
        # Performance metrics
        navigation_timing = driver.execute_script("return window.performance.timing")
        if navigation_timing:
            load_time = navigation_timing["loadEventEnd"] - navigation_timing["navigationStart"]
            results["performance_metrics"]["page_load_time"] = load_time
            print(f"ðŸ“Š Page load time: {{load_time}}ms")
        
        # Final status
        results["status"] = "completed" if len(results["errors"]) == 0 else "completed_with_errors"
        results["end_time"] = time.time()
        results["duration"] = results["end_time"] - results["start_time"]
        
        print(f"ðŸŽ¯ Test completed: {{results['steps_completed']}}/{{results['total_steps']}} steps")
        
    except Exception as e:
        results["status"] = "failed"
        results["error"] = str(e)
        print(f"âŒ Test failed: {{e}}")
        
    finally:
        if driver:
            driver.quit()
    
    # Output results as JSON
    print("\\n" + "="*50)
    print("RESULTS:")
    print(json.dumps(results, indent=2))
    return results

if __name__ == "__main__":
    run_cicd_test()
'''
        
        script_path = "temp_automation_script.py"
        with open(script_path, 'w') as f:
            f.write(script_content)
        
        return script_path
    
    def parse_automation_results(self, stdout: str) -> Dict[str, Any]:
        """Parse results from automation script output"""
        try:
            # Look for JSON results in stdout
            lines = stdout.split('\n')
            json_start = -1
            for i, line in enumerate(lines):
                if line.strip() == "RESULTS:":
                    json_start = i + 1
                    break
            
            if json_start >= 0:
                json_lines = lines[json_start:]
                json_str = '\n'.join(json_lines)
                return json.loads(json_str)
            else:
                # Fallback: create results from stdout
                return {
                    "status": "completed",
                    "stdout": stdout,
                    "parsed": False
                }
        except Exception as e:
            return {
                "status": "parse_error",
                "error": str(e),
                "stdout": stdout
            }
    
    def poll_for_results(self, test_id: str) -> Dict[str, Any]:
        """Poll web-eval-agent API for test results"""
        print(f"â³ Polling for results (test ID: {test_id})...")
        
        max_polls = 60  # 15 minutes with 15-second intervals
        poll_interval = 15
        
        for i in range(max_polls):
            try:
                response = requests.get(
                    f"{self.web_eval_agent_url}/api/test/{test_id}/status",
                    timeout=10
                )
                
                if response.status_code == 200:
                    result = response.json()
                    status = result.get("status")
                    
                    if status in ["completed", "failed", "error"]:
                        print(f"âœ… Test {status}")
                        return result
                    else:
                        print(f"â³ Status: {status} ({i+1}/{max_polls})")
                        time.sleep(poll_interval)
                else:
                    print(f"âš ï¸  API returned {response.status_code}")
                    time.sleep(poll_interval)
                    
            except Exception as e:
                print(f"âš ï¸  Polling error: {e}")
                time.sleep(poll_interval)
        
        return {
            "status": "timeout",
            "error": "Test did not complete within timeout period"
        }
    
    def save_results(self, results: Dict[str, Any]) -> None:
        """Save test results to file"""
        with open(self.results_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ðŸ’¾ Results saved to: {self.results_file}")
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """Generate a human-readable test report"""
        report = []
        report.append("ðŸ§ª WEB-EVAL-AGENT CICD CYCLE TEST REPORT")
        report.append("=" * 60)
        report.append(f"Target URL: {self.target_url}")
        report.append(f"Test Status: {results.get('status', 'unknown')}")
        report.append(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # Test results summary
        if results.get("steps_completed") is not None:
            total_steps = results.get("total_steps", 11)
            completed_steps = results.get("steps_completed", 0)
            report.append(f"Steps Completed: {completed_steps}/{total_steps}")
            report.append(f"Success Rate: {(completed_steps/total_steps)*100:.1f}%")
        
        # Performance metrics
        if results.get("performance_metrics"):
            report.append("")
            report.append("ðŸ“Š PERFORMANCE METRICS:")
            for metric, value in results["performance_metrics"].items():
                report.append(f"  {metric}: {value}")
        
        # Errors
        if results.get("errors"):
            report.append("")
            report.append("âŒ ERRORS ENCOUNTERED:")
            for error in results["errors"]:
                report.append(f"  - {error}")
        
        # Duration
        if results.get("duration"):
            report.append(f"")
            report.append(f"â±ï¸  Total Duration: {results['duration']:.2f} seconds")
        
        # Recommendations
        report.append("")
        report.append("ðŸ’¡ RECOMMENDATIONS:")
        if results.get("status") == "completed":
            report.append("  âœ… All tests passed successfully!")
            report.append("  âœ… CICD cycle is functioning correctly")
        elif results.get("status") == "completed_with_errors":
            report.append("  âš ï¸  Some issues found but core functionality works")
            report.append("  ðŸ”§ Review errors and improve UI/UX")
        else:
            report.append("  âŒ Significant issues found")
            report.append("  ðŸš¨ CICD cycle needs attention before production")
        
        return "\\n".join(report)
    
    def run(self) -> bool:
        """Run the complete test suite"""
        print("ðŸš€ Starting Web-Eval-Agent CICD Cycle Test Suite")
        print("=" * 60)
        
        # Check prerequisites
        if not self.check_prerequisites():
            return False
        
        # Run the test
        results = self.run_web_eval_agent_test()
        
        # Save results
        self.save_results(results)
        
        # Generate and display report
        report = self.generate_report(results)
        print("\\n" + report)
        
        # Return success status
        return results.get("status") in ["completed", "completed_with_errors"]

def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Run Web-Eval-Agent CICD Cycle Test")
    parser.add_argument("--url", default="http://localhost:3001", help="Target URL to test")
    parser.add_argument("--production", action="store_true", help="Test production URL")
    
    args = parser.parse_args()
    
    # Use production URL if specified
    if args.production:
        target_url = "https://uioftheproject.com"
    else:
        target_url = args.url
    
    # Run the test
    tester = WebEvalCICDTester(target_url)
    success = tester.run()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()

